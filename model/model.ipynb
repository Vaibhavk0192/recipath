{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import time\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.10\n",
      "Tensorflow version: 2.12.0\n",
      "Keras version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "print('Python version:', platform.python_version())\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version:', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = './tmp'\n",
    "pathlib.Path(CACHE_DIR).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/datasets/recipes_raw_nosource_ar.json\n",
      "===========================================\n",
      "Number of examples:  39802 \n",
      "\n",
      "Example object keys:\n",
      " ['ingredients', 'instructions', 'picture_link', 'title'] \n",
      "\n",
      "Example object:\n",
      " {'title': 'Slow Cooker Chicken and Dumplings', 'ingredients': ['4 skinless, boneless chicken breast halves ADVERTISEMENT', '2 tablespoons butter ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of chicken soup ADVERTISEMENT', '1 onion, finely diced ADVERTISEMENT', '2 (10 ounce) packages refrigerated biscuit dough, torn into pieces ADVERTISEMENT', 'ADVERTISEMENT'], 'instructions': 'Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\\nCover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\\n', 'picture_link': '55lznCYBbs2mT8BTx6BTkLhynGHzM.S'} \n",
      "\n",
      "Required keys:\n",
      "\n",
      "  title:  Slow Cooker Chicken and Dumplings \n",
      "\n",
      "  ingredients:  ['4 skinless, boneless chicken breast halves ADVERTISEMENT', '2 tablespoons butter ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of chicken soup ADVERTISEMENT', '1 onion, finely diced ADVERTISEMENT', '2 (10 ounce) packages refrigerated biscuit dough, torn into pieces ADVERTISEMENT', 'ADVERTISEMENT'] \n",
      "\n",
      "  instructions:  Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\n",
      "Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "./tmp/datasets/recipes_raw_nosource_epi.json\n",
      "===========================================\n",
      "Number of examples:  25323 \n",
      "\n",
      "Example object keys:\n",
      " ['ingredients', 'instructions', 'picture_link', 'title'] \n",
      "\n",
      "Example object:\n",
      " {'ingredients': ['12 egg whites', '12 egg yolks', '1 1/2 cups sugar', '3/4 cup rye whiskey', '12 egg whites', '3/4 cup brandy', '1/2 cup rum', '1 to 2 cups heavy cream, lightly whipped', 'Garnish: ground nutmeg'], 'picture_link': None, 'instructions': 'Beat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\\nBeat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.', 'title': 'Christmas Eggnog '} \n",
      "\n",
      "Required keys:\n",
      "\n",
      "  title:  Christmas Eggnog  \n",
      "\n",
      "  ingredients:  ['12 egg whites', '12 egg yolks', '1 1/2 cups sugar', '3/4 cup rye whiskey', '12 egg whites', '3/4 cup brandy', '1/2 cup rum', '1 to 2 cups heavy cream, lightly whipped', 'Garnish: ground nutmeg'] \n",
      "\n",
      "  instructions:  Beat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\n",
      "Beat the egg whites until stiff, gradually adding in 3/4 cup sugar. Set aside. Beat the egg yolks until they are thick and pale and add the other 3/4 cup sugar and stir in rye whiskey. Blend well. Fold the egg white mixture into the yolk mixture and add the brandy and the rum. Beat the mixture well. To serve, fold the lightly whipped heavy cream into the eggnog. (If a thinner mixture is desired, add the heavy cream unwhipped.) Sprinkle the top of the eggnog with the nutmeg to taste.\n",
      "\n",
      "\n",
      "\n",
      "./tmp/datasets/recipes_raw_nosource_fn.json\n",
      "===========================================\n",
      "Number of examples:  60039 \n",
      "\n",
      "Example object keys:\n",
      " ['ingredients', 'instructions', 'picture_link', 'title'] \n",
      "\n",
      "Example object:\n",
      " {'instructions': 'Toss ingredients lightly and spoon into a buttered baking dish. Top with additional crushed cracker crumbs, and brush with melted butter. Bake in a preheated at 350 degrees oven for 25 to 30 minutes or until delicately browned.', 'ingredients': ['1/2 cup celery, finely chopped', '1 small green pepper finely chopped', '1/2 cup finely sliced green onions', '1/4 cup chopped parsley', '1 pound crabmeat', '1 1/4 cups coarsely crushed cracker crumbs', '1/2 teaspoon salt', '3/4 teaspoons dry mustard', 'Dash hot sauce', '1/4 cup heavy cream', '1/2 cup melted butter'], 'title': \"Grammie Hamblet's Deviled Crab\", 'picture_link': None} \n",
      "\n",
      "Required keys:\n",
      "\n",
      "  title:  Grammie Hamblet's Deviled Crab \n",
      "\n",
      "  ingredients:  ['1/2 cup celery, finely chopped', '1 small green pepper finely chopped', '1/2 cup finely sliced green onions', '1/4 cup chopped parsley', '1 pound crabmeat', '1 1/4 cups coarsely crushed cracker crumbs', '1/2 teaspoon salt', '3/4 teaspoons dry mustard', 'Dash hot sauce', '1/4 cup heavy cream', '1/2 cup melted butter'] \n",
      "\n",
      "  instructions:  Toss ingredients lightly and spoon into a buttered baking dish. Top with additional crushed cracker crumbs, and brush with melted butter. Bake in a preheated at 350 degrees oven for 25 to 30 minutes or until delicately browned.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(silent=False):\n",
    "    # List of dataset files we want to merge.\n",
    "    dataset_file_names = [\n",
    "        'recipes_raw_nosource_ar.json',\n",
    "        'recipes_raw_nosource_epi.json',\n",
    "        'recipes_raw_nosource_fn.json',\n",
    "    ]\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    for dataset_file_name in dataset_file_names:\n",
    "        dataset_file_path = f'{CACHE_DIR}/datasets/{dataset_file_name}'\n",
    "\n",
    "        with open(dataset_file_path) as dataset_file:\n",
    "            json_data_dict = json.load(dataset_file)\n",
    "            json_data_list = list(json_data_dict.values())\n",
    "            dict_keys = [key for key in json_data_list[0]]\n",
    "            dict_keys.sort()\n",
    "            dataset += json_data_list\n",
    "\n",
    "            # This code block outputs the summary for each dataset.\n",
    "            if silent == False:\n",
    "                print(dataset_file_path)\n",
    "                print('===========================================')\n",
    "                print('Number of examples: ', len(json_data_list), '\\n')\n",
    "                print('Example object keys:\\n', dict_keys, '\\n')\n",
    "                print('Example object:\\n', json_data_list[0], '\\n')\n",
    "                print('Required keys:\\n')\n",
    "                print('  title: ', json_data_list[0]['title'], '\\n')\n",
    "                print('  ingredients: ', json_data_list[0]['ingredients'], '\\n')\n",
    "                print('  instructions: ', json_data_list[0]['instructions'])\n",
    "                print('\\n\\n')\n",
    "\n",
    "    return dataset  \n",
    "\n",
    "dataset_raw = load_dataset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of raw examples:  125164\n"
     ]
    }
   ],
   "source": [
    "print('Total number of raw examples: ', len(dataset_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_validate_required_fields(recipe):\n",
    "    required_keys = ['title', 'ingredients', 'instructions']\n",
    "    \n",
    "    if not recipe:\n",
    "        return False\n",
    "    \n",
    "    for required_key in required_keys:\n",
    "        if not recipe[required_key]:\n",
    "            return False\n",
    "        \n",
    "        if type(recipe[required_key]) == list and len(recipe[required_key]) == 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size BEFORE validation 125164\n",
      "Dataset size AFTER validation 122938\n",
      "Number of incomplete recipes 2226\n"
     ]
    }
   ],
   "source": [
    "dataset_validated = [recipe for recipe in dataset_raw if recipe_validate_required_fields(recipe)]\n",
    "\n",
    "print('Dataset size BEFORE validation', len(dataset_raw))\n",
    "print('Dataset size AFTER validation', len(dataset_validated))\n",
    "print('Number of incomplete recipes', len(dataset_raw) - len(dataset_validated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORD_TITLE = 'üìó '\n",
    "STOP_WORD_INGREDIENTS = '\\nü•ï\\n\\n'\n",
    "STOP_WORD_INSTRUCTIONS = '\\nüìù\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_to_string(recipe):\n",
    "    # This string is presented as a part of recipes so we need to clean it up.\n",
    "    noize_string = 'ADVERTISEMENT'\n",
    "    \n",
    "    title = recipe['title']\n",
    "    ingredients = recipe['ingredients']\n",
    "    instructions = recipe['instructions'].split('\\n')\n",
    "    \n",
    "    ingredients_string = ''\n",
    "    for ingredient in ingredients:\n",
    "        ingredient = ingredient.replace(noize_string, '')\n",
    "        if ingredient:\n",
    "            ingredients_string += f'‚Ä¢ {ingredient}\\n'\n",
    "    \n",
    "    instructions_string = ''\n",
    "    for instruction in instructions:\n",
    "        instruction = instruction.replace(noize_string, '')\n",
    "        if instruction:\n",
    "            instructions_string += f'‚ñ™Ô∏é {instruction}\\n'\n",
    "    \n",
    "    return f'{STOP_WORD_TITLE}{title}\\n{STOP_WORD_INGREDIENTS}{ingredients_string}{STOP_WORD_INSTRUCTIONS}{instructions_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stringified dataset size:  122938\n"
     ]
    }
   ],
   "source": [
    "dataset_stringified = [recipe_to_string(recipe) for recipe in dataset_validated]\n",
    "\n",
    "print('Stringified dataset size: ', len(dataset_stringified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #1\n",
      "---------\n",
      "üìó Slow Cooker Chicken and Dumplings\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 4 skinless, boneless chicken breast halves \n",
      "‚Ä¢ 2 tablespoons butter \n",
      "‚Ä¢ 2 (10.75 ounce) cans condensed cream of chicken soup \n",
      "‚Ä¢ 1 onion, finely diced \n",
      "‚Ä¢ 2 (10 ounce) packages refrigerated biscuit dough, torn into pieces \n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Place the chicken, butter, soup, and onion in a slow cooker, and fill with enough water to cover.\n",
      "‚ñ™Ô∏é Cover, and cook for 5 to 6 hours on High. About 30 minutes before serving, place the torn biscuit dough in the slow cooker. Cook until the dough is no longer raw in the center.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #2\n",
      "---------\n",
      "üìó Awesome Slow Cooker Pot Roast\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 2 (10.75 ounce) cans condensed cream of mushroom soup \n",
      "‚Ä¢ 1 (1 ounce) package dry onion soup mix \n",
      "‚Ä¢ 1 1/4 cups water \n",
      "‚Ä¢ 5 1/2 pounds pot roast \n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é In a slow cooker, mix cream of mushroom soup, dry onion soup mix and water. Place pot roast in slow cooker and coat with soup mixture.\n",
      "‚ñ™Ô∏é Cook on High setting for 3 to 4 hours, or on Low setting for 8 to 9 hours.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #3\n",
      "---------\n",
      "üìó Brown Sugar Meatloaf\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1/2 cup packed brown sugar \n",
      "‚Ä¢ 1/2 cup ketchup \n",
      "‚Ä¢ 1 1/2 pounds lean ground beef \n",
      "‚Ä¢ 3/4 cup milk \n",
      "‚Ä¢ 2 eggs \n",
      "‚Ä¢ 1 1/2 teaspoons salt \n",
      "‚Ä¢ 1/4 teaspoon ground black pepper \n",
      "‚Ä¢ 1 small onion, chopped \n",
      "‚Ä¢ 1/4 teaspoon ground ginger \n",
      "‚Ä¢ 3/4 cup finely crushed saltine cracker crumbs \n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Preheat oven to 350 degrees F (175 degrees C). Lightly grease a 5x9 inch loaf pan.\n",
      "‚ñ™Ô∏é Press the brown sugar in the bottom of the prepared loaf pan and spread the ketchup over the sugar.\n",
      "‚ñ™Ô∏é In a mixing bowl, mix thoroughly all remaining ingredients and shape into a loaf. Place on top of the ketchup.\n",
      "‚ñ™Ô∏é Bake in preheated oven for 1 hour or until juices are clear.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for recipe_index, recipe_string in enumerate(dataset_stringified[:3]):\n",
    "    print('Recipe #{}\\n---------'.format(recipe_index + 1))\n",
    "    print(recipe_string)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Herbed Bean Rago√ªt \n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 6 ounces haricots verts (French thin green beans), trimmed and halved crosswise\n",
      "‚Ä¢ 1 (1-pound) bag frozen edamame (soybeans in the pod) or 1 1/4 cups frozen shelled edamame, not thawed\n",
      "‚Ä¢ 2/3 cup finely chopped onion\n",
      "‚Ä¢ 2 garlic cloves, minced\n",
      "‚Ä¢ 1 Turkish bay leaf or 1/2 California bay leaf\n",
      "‚Ä¢ 2 (3-inch) fresh rosemary sprigs\n",
      "‚Ä¢ 1/2 teaspoon salt\n",
      "‚Ä¢ 1/4 teaspoon black pepper\n",
      "‚Ä¢ 1 tablespoon olive oil\n",
      "‚Ä¢ 1 medium carrot, cut into 1/8-inch dice\n",
      "‚Ä¢ 1 medium celery rib, cut into 1/8-inch dice\n",
      "‚Ä¢ 1 (15- to 16-ounces) can small white beans, rinsed and drained\n",
      "‚Ä¢ 1 1/2 cups chicken stock or low-sodium broth\n",
      "‚Ä¢ 2 tablespoons unsalted butter\n",
      "‚Ä¢ 2 tablespoons finely chopped fresh flat-leaf parsley\n",
      "‚Ä¢ 1 tablespoon finely chopped fresh chervil (optional)\n",
      "‚Ä¢ Garnish: fresh chervil sprigs\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Cook haricots verts in a large pot of boiling salted water until just tender, 3 to 4 minutes. Transfer with a slotted spoon to a bowl of ice and cold water, then drain. Add edamame to boiling water and cook 4 minutes. Drain in a colander, then rinse under cold water. If using edamame in pods, shell them and discard pods. Cook onion, garlic, bay leaf, rosemary, salt, and pepper in oil in a 2- to 4-quart heavy saucepan over moderately low heat, stirring, until softened, about 3 minutes. Add carrot and celery and cook, stirring, until softened, about 3 minutes. Add white beans and stock and simmer, covered, stirring occasionally, 10 minutes. Add haricots verts and edamame and simmer, uncovered, until heated through, 2 to 3 minutes. Add butter, parsley, and chervil (if using) and stir gently until butter is melted. Discard bay leaf and rosemary sprigs.\n",
      "‚ñ™Ô∏é Cook haricots verts in a large pot of boiling salted water until just tender, 3 to 4 minutes. Transfer with a slotted spoon to a bowl of ice and cold water, then drain.\n",
      "‚ñ™Ô∏é Add edamame to boiling water and cook 4 minutes. Drain in a colander, then rinse under cold water. If using edamame in pods, shell them and discard pods.\n",
      "‚ñ™Ô∏é Cook onion, garlic, bay leaf, rosemary, salt, and pepper in oil in a 2- to 4-quart heavy saucepan over moderately low heat, stirring, until softened, about 3 minutes. Add carrot and celery and cook, stirring, until softened, about 3 minutes.\n",
      "‚ñ™Ô∏é Add white beans and stock and simmer, covered, stirring occasionally, 10 minutes. Add haricots verts and edamame and simmer, uncovered, until heated through, 2 to 3 minutes. Add butter, parsley, and chervil (if using) and stir gently until butter is melted. Discard bay leaf and rosemary sprigs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_stringified[50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recipes_lengths = []\n",
    "for recipe_text in dataset_stringified:\n",
    "    recipes_lengths.append(len(recipe_text))\n",
    "\n",
    "plt.hist(recipes_lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(recipes_lengths, range=(0, 8000), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RECIPE_LENGTH = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size BEFORE filtering:  122938\n",
      "Dataset size AFTER filtering:  100212\n",
      "Number of eliminated recipes:  22726\n"
     ]
    }
   ],
   "source": [
    "def filter_recipes_by_length(recipe_test):\n",
    "    return len(recipe_test) <= MAX_RECIPE_LENGTH \n",
    "\n",
    "dataset_filtered = [recipe_text for recipe_text in dataset_stringified if filter_recipes_by_length(recipe_text)]\n",
    "\n",
    "print('Dataset size BEFORE filtering: ', len(dataset_stringified))\n",
    "print('Dataset size AFTER filtering: ', len(dataset_filtered))\n",
    "print('Number of eliminated recipes: ', len(dataset_stringified) - len(dataset_filtered)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_RECIPE_LENGTH:  2000\n",
      "TOTAL_RECIPES_NUM:  100212\n"
     ]
    }
   ],
   "source": [
    "TOTAL_RECIPES_NUM = len(dataset_filtered)\n",
    "\n",
    "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
    "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': None,\n",
       " 'filters': '',\n",
       " 'lower': False,\n",
       " 'split': '',\n",
       " 'char_level': True,\n",
       " 'oov_token': None,\n",
       " 'document_count': 100213,\n",
       " 'word_counts': '{\"\\\\u2423\": 1, \"\\\\ud83d\\\\udcd7\": 100212, \" \": 17527888, \"S\": 270259, \"l\": 3815150, \"o\": 5987496, \"w\": 964459, \"C\": 222831, \"k\": 890982, \"e\": 9296022, \"r\": 4760887, \"h\": 2922100, \"i\": 4911812, \"c\": 2883507, \"n\": 5304396, \"a\": 6067157, \"d\": 3099679, \"D\": 63999, \"u\": 2717050, \"m\": 1794411, \"p\": 2679164, \"g\": 1698670, \"s\": 4704222, \"\\\\n\": 1955281, \"\\\\ud83e\\\\udd55\": 100212, \"\\\\u2022\": 922813, \"4\": 232607, \",\": 1130487, \"b\": 1394803, \"t\": 5997722, \"v\": 746785, \"2\": 493933, \"(\": 144985, \"1\": 853931, \"0\": 145119, \".\": 1052548, \"7\": 31098, \"5\": 154071, \")\": 144977, \"f\": 1042981, \"y\": 666553, \"\\\\ud83d\\\\udcdd\": 100212, \"\\\\u25aa\": 331058, \"\\\\ufe0e\": 331058, \"P\": 200597, \"6\": 51398, \"H\": 43936, \"A\": 134274, \"3\": 213519, \"R\": 101253, \"x\": 201286, \"/\": 345257, \"I\": 81591, \"L\": 46138, \"8\": 55352, \"9\": 17697, \"B\": 123813, \"M\": 78684, \"F\": 104359, \"j\": 110008, \"-\": 219160, \"W\": 61616, \"\\\\u00ae\": 10159, \"N\": 12808, \"q\": 69654, \"T\": 101371, \";\": 72045, \"\\'\": 26831, \"Z\": 2428, \"z\": 115883, \"G\": 52043, \":\": 31318, \"E\": 18582, \"K\": 18421, \"X\": 385, \"\\\\\"\": 6445, \"O\": 28971, \"Y\": 6064, \"\\\\u2122\": 538, \"Q\": 3904, \"J\": 10269, \"!\": 3014, \"U\": 14132, \"V\": 12172, \"&\": 1039, \"+\": 87, \"=\": 113, \"%\": 993, \"*\": 3243, \"\\\\u00a9\": 99, \"[\": 30, \"]\": 31, \"\\\\u00e9\": 6727, \"<\": 76, \">\": 86, \"\\\\u00bd\": 166, \"#\": 168, \"\\\\u00f1\": 891, \"?\": 327, \"\\\\u2019\": 111, \"\\\\u00b0\": 6808, \"\\\\u201d\": 6, \"$\": 84, \"@\": 5, \"{\": 8, \"}\": 9, \"\\\\u2013\": 1228, \"\\\\u0096\": 7, \"\\\\u00e0\": 26, \"\\\\u00e2\": 106, \"\\\\u00e8\": 846, \"\\\\u00e1\": 74, \"\\\\u2014\": 215, \"\\\\u2044\": 16, \"\\\\u00ee\": 415, \"\\\\u00e7\": 171, \"_\": 26, \"\\\\u00fa\": 48, \"\\\\u00ef\": 43, \"\\\\u201a\": 20, \"\\\\u00fb\": 36, \"\\\\u00f3\": 74, \"\\\\u00ed\": 130, \"\\\\u25ca\": 4, \"\\\\u00f9\": 12, \"\\\\u00d7\": 6, \"\\\\u00ec\": 8, \"\\\\u00fc\": 29, \"\\\\u2031\": 4, \"\\\\u00ba\": 19, \"\\\\u201c\": 4, \"\\\\u00ad\": 25, \"\\\\u00ea\": 27, \"\\\\u00f6\": 9, \"\\\\u0301\": 11, \"\\\\u00f4\": 8, \"\\\\u00c1\": 2, \"\\\\u00be\": 23, \"\\\\u00bc\": 95, \"\\\\u00eb\": 2, \"\\\\u0097\": 2, \"\\\\u215b\": 3, \"\\\\u2027\": 4, \"\\\\u00e4\": 15, \"\\\\u001a\": 2, \"\\\\u00f8\": 2, \"\\\\ufffd\": 20, \"\\\\u02da\": 6, \"\\\\u00bf\": 264, \"\\\\u2153\": 2, \"|\": 2, \"\\\\u00e5\": 3, \"\\\\u00a4\": 1, \"\\\\u201f\": 1, \"\\\\u00a7\": 5, \"\\\\ufb02\": 3, \"\\\\u00a0\": 1, \"\\\\u01b0\": 2, \"\\\\u01a1\": 1, \"\\\\u0103\": 1, \"\\\\u0300\": 1, \"\\\\u00bb\": 6, \"`\": 3, \"\\\\u0092\": 2, \"\\\\u215e\": 1, \"\\\\u202d\": 4, \"\\\\u00b4\": 2, \"\\\\u2012\": 2, \"\\\\u00c9\": 40, \"\\\\u00da\": 14, \"\\\\u20ac\": 1, \"\\\\\\\\\": 5, \"~\": 1, \"\\\\u0095\": 1, \"\\\\u00c2\": 2}',\n",
       " 'word_docs': '{\"\\\\u2423\": 1, \".\": 100163, \"S\": 89250, \"u\": 100161, \"l\": 100206, \"o\": 100205, \"f\": 98331, \",\": 98524, \"p\": 100046, \"1\": 99320, \"0\": 61954, \"s\": 100204, \"5\": 65486, \"\\\\u25aa\": 100212, \"\\\\ud83d\\\\udcd7\": 100212, \"(\": 67627, \"D\": 40870, \"g\": 99975, \"\\\\n\": 100212, \"\\\\u2022\": 100212, \"e\": 100212, \"r\": 100207, \"n\": 100198, \"7\": 24377, \"a\": 100205, \"H\": 31908, \"i\": 100207, \"\\\\ud83e\\\\udd55\": 100212, \"b\": 99702, \"y\": 96387, \"2\": 96743, \")\": 67614, \"A\": 60900, \"\\\\ud83d\\\\udcdd\": 100212, \"\\\\ufe0e\": 100212, \"P\": 79364, \"k\": 97316, \"C\": 83328, \"4\": 82453, \"d\": 100194, \"3\": 79135, \" \": 100212, \"v\": 97848, \"t\": 100202, \"m\": 99988, \"h\": 100161, \"w\": 99227, \"6\": 35206, \"c\": 100190, \"x\": 72133, \"/\": 89051, \"R\": 54040, \"I\": 46675, \"L\": 32101, \"9\": 14114, \"8\": 37000, \"F\": 57940, \"M\": 48332, \"B\": 64278, \"j\": 47438, \"-\": 74711, \"T\": 53758, \"q\": 36538, \"W\": 38981, \"N\": 9981, \"\\\\u00ae\": 5819, \";\": 33863, \"G\": 35355, \"z\": 42430, \"\\'\": 18120, \"Z\": 2184, \":\": 18214, \"E\": 12161, \"K\": 14834, \"X\": 321, \"\\\\\"\": 2617, \"O\": 20103, \"Y\": 5148, \"\\\\u2122\": 448, \"Q\": 3142, \"J\": 8225, \"!\": 2428, \"U\": 10621, \"V\": 9710, \"&\": 749, \"=\": 48, \"+\": 32, \"%\": 717, \"*\": 1780, \"\\\\u00a9\": 91, \"]\": 26, \"[\": 25, \"\\\\u00e9\": 2462, \"<\": 27, \">\": 33, \"\\\\u00bd\": 81, \"#\": 139, \"\\\\u00f1\": 423, \"?\": 207, \"\\\\u2019\": 64, \"\\\\u00b0\": 3062, \"\\\\u201d\": 3, \"@\": 4, \"$\": 49, \"{\": 7, \"}\": 8, \"\\\\u2013\": 491, \"\\\\u0096\": 7, \"\\\\u00e0\": 22, \"\\\\u00e2\": 45, \"\\\\u00e8\": 335, \"\\\\u00e1\": 38, \"\\\\u2014\": 95, \"\\\\u2044\": 9, \"\\\\u00ee\": 122, \"_\": 8, \"\\\\u00e7\": 120, \"\\\\u00fa\": 25, \"\\\\u00ef\": 24, \"\\\\u201a\": 10, \"\\\\u00fb\": 29, \"\\\\u00f3\": 40, \"\\\\u00ed\": 52, \"\\\\u25ca\": 2, \"\\\\u00f9\": 6, \"\\\\u00d7\": 4, \"\\\\u00ec\": 4, \"\\\\u00fc\": 19, \"\\\\u2031\": 2, \"\\\\u00ba\": 9, \"\\\\u201c\": 2, \"\\\\u00ad\": 11, \"\\\\u00ea\": 4, \"\\\\u00f6\": 4, \"\\\\u0301\": 6, \"\\\\u00f4\": 5, \"\\\\u00c1\": 2, \"\\\\u00be\": 18, \"\\\\u00bc\": 55, \"\\\\u00eb\": 2, \"\\\\u0097\": 1, \"\\\\u215b\": 2, \"\\\\u2027\": 3, \"\\\\u00e4\": 8, \"\\\\u001a\": 1, \"\\\\u00f8\": 1, \"\\\\ufffd\": 4, \"\\\\u02da\": 3, \"\\\\u00bf\": 191, \"\\\\u2153\": 1, \"|\": 2, \"\\\\u00e5\": 1, \"\\\\u00a4\": 1, \"\\\\u201f\": 1, \"\\\\u00a7\": 3, \"\\\\ufb02\": 1, \"\\\\u01a1\": 1, \"\\\\u0103\": 1, \"\\\\u01b0\": 1, \"\\\\u0300\": 1, \"\\\\u00a0\": 1, \"\\\\u00bb\": 2, \"`\": 3, \"\\\\u0092\": 2, \"\\\\u215e\": 1, \"\\\\u202d\": 1, \"\\\\u00b4\": 1, \"\\\\u2012\": 1, \"\\\\u00c9\": 15, \"\\\\u00da\": 5, \"\\\\u20ac\": 1, \"\\\\\\\\\": 5, \"~\": 1, \"\\\\u0095\": 1, \"\\\\u00c2\": 1}',\n",
       " 'index_docs': '{\"1\": 100212, \"165\": 1, \"21\": 100163, \"33\": 89250, \"14\": 100161, \"10\": 100206, \"5\": 100205, \"22\": 98331, \"20\": 98524, \"15\": 100046, \"26\": 99320, \"41\": 61954, \"9\": 100204, \"40\": 65486, \"31\": 100212, \"51\": 100212, \"42\": 67627, \"58\": 40870, \"18\": 99975, \"16\": 100212, \"24\": 100212, \"2\": 100212, \"8\": 100207, \"6\": 100198, \"66\": 24377, \"3\": 100205, \"64\": 31908, \"7\": 100207, \"52\": 100212, \"19\": 99702, \"28\": 96387, \"29\": 96743, \"43\": 67614, \"44\": 60900, \"53\": 100212, \"32\": 100212, \"39\": 79364, \"25\": 97316, \"35\": 83328, \"34\": 82453, \"11\": 100194, \"37\": 79135, \"27\": 97848, \"4\": 100202, \"17\": 99988, \"12\": 100161, \"23\": 99227, \"62\": 35206, \"13\": 100190, \"38\": 72133, \"30\": 89051, \"50\": 54040, \"54\": 46675, \"63\": 32101, \"71\": 14114, \"60\": 37000, \"48\": 57940, \"55\": 48332, \"45\": 64278, \"47\": 47438, \"36\": 74711, \"49\": 53758, \"57\": 36538, \"59\": 38981, \"73\": 9981, \"76\": 5819, \"56\": 33863, \"61\": 35355, \"46\": 42430, \"68\": 18120, \"84\": 2184, \"65\": 18214, \"69\": 12161, \"70\": 14834, \"92\": 321, \"79\": 2617, \"67\": 20103, \"80\": 5148, \"90\": 448, \"81\": 3142, \"75\": 8225, \"83\": 2428, \"72\": 10621, \"74\": 9710, \"86\": 749, \"100\": 48, \"105\": 32, \"87\": 717, \"82\": 1780, \"103\": 91, \"115\": 26, \"116\": 25, \"78\": 2462, \"108\": 27, \"106\": 33, \"98\": 81, \"97\": 139, \"88\": 423, \"93\": 207, \"101\": 64, \"77\": 3062, \"137\": 3, \"141\": 4, \"107\": 49, \"133\": 7, \"131\": 8, \"85\": 491, \"136\": 7, \"119\": 22, \"102\": 45, \"89\": 335, \"109\": 38, \"95\": 95, \"126\": 9, \"91\": 122, \"120\": 8, \"96\": 120, \"111\": 25, \"112\": 24, \"123\": 10, \"114\": 29, \"110\": 40, \"99\": 52, \"144\": 2, \"129\": 6, \"138\": 4, \"134\": 4, \"117\": 19, \"145\": 2, \"125\": 9, \"146\": 2, \"121\": 11, \"118\": 4, \"132\": 4, \"130\": 6, \"135\": 5, \"153\": 2, \"122\": 18, \"104\": 55, \"154\": 2, \"155\": 1, \"149\": 2, \"147\": 3, \"127\": 8, \"156\": 1, \"157\": 1, \"124\": 4, \"139\": 3, \"94\": 191, \"158\": 1, \"159\": 2, \"150\": 1, \"166\": 1, \"167\": 1, \"142\": 3, \"151\": 1, \"169\": 1, \"170\": 1, \"160\": 1, \"171\": 1, \"168\": 1, \"140\": 2, \"152\": 3, \"161\": 2, \"172\": 1, \"148\": 1, \"162\": 1, \"163\": 1, \"113\": 15, \"128\": 5, \"173\": 1, \"143\": 5, \"174\": 1, \"175\": 1, \"164\": 1}',\n",
       " 'index_word': '{\"1\": \" \", \"2\": \"e\", \"3\": \"a\", \"4\": \"t\", \"5\": \"o\", \"6\": \"n\", \"7\": \"i\", \"8\": \"r\", \"9\": \"s\", \"10\": \"l\", \"11\": \"d\", \"12\": \"h\", \"13\": \"c\", \"14\": \"u\", \"15\": \"p\", \"16\": \"\\\\n\", \"17\": \"m\", \"18\": \"g\", \"19\": \"b\", \"20\": \",\", \"21\": \".\", \"22\": \"f\", \"23\": \"w\", \"24\": \"\\\\u2022\", \"25\": \"k\", \"26\": \"1\", \"27\": \"v\", \"28\": \"y\", \"29\": \"2\", \"30\": \"/\", \"31\": \"\\\\u25aa\", \"32\": \"\\\\ufe0e\", \"33\": \"S\", \"34\": \"4\", \"35\": \"C\", \"36\": \"-\", \"37\": \"3\", \"38\": \"x\", \"39\": \"P\", \"40\": \"5\", \"41\": \"0\", \"42\": \"(\", \"43\": \")\", \"44\": \"A\", \"45\": \"B\", \"46\": \"z\", \"47\": \"j\", \"48\": \"F\", \"49\": \"T\", \"50\": \"R\", \"51\": \"\\\\ud83d\\\\udcd7\", \"52\": \"\\\\ud83e\\\\udd55\", \"53\": \"\\\\ud83d\\\\udcdd\", \"54\": \"I\", \"55\": \"M\", \"56\": \";\", \"57\": \"q\", \"58\": \"D\", \"59\": \"W\", \"60\": \"8\", \"61\": \"G\", \"62\": \"6\", \"63\": \"L\", \"64\": \"H\", \"65\": \":\", \"66\": \"7\", \"67\": \"O\", \"68\": \"\\'\", \"69\": \"E\", \"70\": \"K\", \"71\": \"9\", \"72\": \"U\", \"73\": \"N\", \"74\": \"V\", \"75\": \"J\", \"76\": \"\\\\u00ae\", \"77\": \"\\\\u00b0\", \"78\": \"\\\\u00e9\", \"79\": \"\\\\\"\", \"80\": \"Y\", \"81\": \"Q\", \"82\": \"*\", \"83\": \"!\", \"84\": \"Z\", \"85\": \"\\\\u2013\", \"86\": \"&\", \"87\": \"%\", \"88\": \"\\\\u00f1\", \"89\": \"\\\\u00e8\", \"90\": \"\\\\u2122\", \"91\": \"\\\\u00ee\", \"92\": \"X\", \"93\": \"?\", \"94\": \"\\\\u00bf\", \"95\": \"\\\\u2014\", \"96\": \"\\\\u00e7\", \"97\": \"#\", \"98\": \"\\\\u00bd\", \"99\": \"\\\\u00ed\", \"100\": \"=\", \"101\": \"\\\\u2019\", \"102\": \"\\\\u00e2\", \"103\": \"\\\\u00a9\", \"104\": \"\\\\u00bc\", \"105\": \"+\", \"106\": \">\", \"107\": \"$\", \"108\": \"<\", \"109\": \"\\\\u00e1\", \"110\": \"\\\\u00f3\", \"111\": \"\\\\u00fa\", \"112\": \"\\\\u00ef\", \"113\": \"\\\\u00c9\", \"114\": \"\\\\u00fb\", \"115\": \"]\", \"116\": \"[\", \"117\": \"\\\\u00fc\", \"118\": \"\\\\u00ea\", \"119\": \"\\\\u00e0\", \"120\": \"_\", \"121\": \"\\\\u00ad\", \"122\": \"\\\\u00be\", \"123\": \"\\\\u201a\", \"124\": \"\\\\ufffd\", \"125\": \"\\\\u00ba\", \"126\": \"\\\\u2044\", \"127\": \"\\\\u00e4\", \"128\": \"\\\\u00da\", \"129\": \"\\\\u00f9\", \"130\": \"\\\\u0301\", \"131\": \"}\", \"132\": \"\\\\u00f6\", \"133\": \"{\", \"134\": \"\\\\u00ec\", \"135\": \"\\\\u00f4\", \"136\": \"\\\\u0096\", \"137\": \"\\\\u201d\", \"138\": \"\\\\u00d7\", \"139\": \"\\\\u02da\", \"140\": \"\\\\u00bb\", \"141\": \"@\", \"142\": \"\\\\u00a7\", \"143\": \"\\\\\\\\\", \"144\": \"\\\\u25ca\", \"145\": \"\\\\u2031\", \"146\": \"\\\\u201c\", \"147\": \"\\\\u2027\", \"148\": \"\\\\u202d\", \"149\": \"\\\\u215b\", \"150\": \"\\\\u00e5\", \"151\": \"\\\\ufb02\", \"152\": \"`\", \"153\": \"\\\\u00c1\", \"154\": \"\\\\u00eb\", \"155\": \"\\\\u0097\", \"156\": \"\\\\u001a\", \"157\": \"\\\\u00f8\", \"158\": \"\\\\u2153\", \"159\": \"|\", \"160\": \"\\\\u01b0\", \"161\": \"\\\\u0092\", \"162\": \"\\\\u00b4\", \"163\": \"\\\\u2012\", \"164\": \"\\\\u00c2\", \"165\": \"\\\\u2423\", \"166\": \"\\\\u00a4\", \"167\": \"\\\\u201f\", \"168\": \"\\\\u00a0\", \"169\": \"\\\\u01a1\", \"170\": \"\\\\u0103\", \"171\": \"\\\\u0300\", \"172\": \"\\\\u215e\", \"173\": \"\\\\u20ac\", \"174\": \"~\", \"175\": \"\\\\u0095\"}',\n",
       " 'word_index': '{\" \": 1, \"e\": 2, \"a\": 3, \"t\": 4, \"o\": 5, \"n\": 6, \"i\": 7, \"r\": 8, \"s\": 9, \"l\": 10, \"d\": 11, \"h\": 12, \"c\": 13, \"u\": 14, \"p\": 15, \"\\\\n\": 16, \"m\": 17, \"g\": 18, \"b\": 19, \",\": 20, \".\": 21, \"f\": 22, \"w\": 23, \"\\\\u2022\": 24, \"k\": 25, \"1\": 26, \"v\": 27, \"y\": 28, \"2\": 29, \"/\": 30, \"\\\\u25aa\": 31, \"\\\\ufe0e\": 32, \"S\": 33, \"4\": 34, \"C\": 35, \"-\": 36, \"3\": 37, \"x\": 38, \"P\": 39, \"5\": 40, \"0\": 41, \"(\": 42, \")\": 43, \"A\": 44, \"B\": 45, \"z\": 46, \"j\": 47, \"F\": 48, \"T\": 49, \"R\": 50, \"\\\\ud83d\\\\udcd7\": 51, \"\\\\ud83e\\\\udd55\": 52, \"\\\\ud83d\\\\udcdd\": 53, \"I\": 54, \"M\": 55, \";\": 56, \"q\": 57, \"D\": 58, \"W\": 59, \"8\": 60, \"G\": 61, \"6\": 62, \"L\": 63, \"H\": 64, \":\": 65, \"7\": 66, \"O\": 67, \"\\'\": 68, \"E\": 69, \"K\": 70, \"9\": 71, \"U\": 72, \"N\": 73, \"V\": 74, \"J\": 75, \"\\\\u00ae\": 76, \"\\\\u00b0\": 77, \"\\\\u00e9\": 78, \"\\\\\"\": 79, \"Y\": 80, \"Q\": 81, \"*\": 82, \"!\": 83, \"Z\": 84, \"\\\\u2013\": 85, \"&\": 86, \"%\": 87, \"\\\\u00f1\": 88, \"\\\\u00e8\": 89, \"\\\\u2122\": 90, \"\\\\u00ee\": 91, \"X\": 92, \"?\": 93, \"\\\\u00bf\": 94, \"\\\\u2014\": 95, \"\\\\u00e7\": 96, \"#\": 97, \"\\\\u00bd\": 98, \"\\\\u00ed\": 99, \"=\": 100, \"\\\\u2019\": 101, \"\\\\u00e2\": 102, \"\\\\u00a9\": 103, \"\\\\u00bc\": 104, \"+\": 105, \">\": 106, \"$\": 107, \"<\": 108, \"\\\\u00e1\": 109, \"\\\\u00f3\": 110, \"\\\\u00fa\": 111, \"\\\\u00ef\": 112, \"\\\\u00c9\": 113, \"\\\\u00fb\": 114, \"]\": 115, \"[\": 116, \"\\\\u00fc\": 117, \"\\\\u00ea\": 118, \"\\\\u00e0\": 119, \"_\": 120, \"\\\\u00ad\": 121, \"\\\\u00be\": 122, \"\\\\u201a\": 123, \"\\\\ufffd\": 124, \"\\\\u00ba\": 125, \"\\\\u2044\": 126, \"\\\\u00e4\": 127, \"\\\\u00da\": 128, \"\\\\u00f9\": 129, \"\\\\u0301\": 130, \"}\": 131, \"\\\\u00f6\": 132, \"{\": 133, \"\\\\u00ec\": 134, \"\\\\u00f4\": 135, \"\\\\u0096\": 136, \"\\\\u201d\": 137, \"\\\\u00d7\": 138, \"\\\\u02da\": 139, \"\\\\u00bb\": 140, \"@\": 141, \"\\\\u00a7\": 142, \"\\\\\\\\\": 143, \"\\\\u25ca\": 144, \"\\\\u2031\": 145, \"\\\\u201c\": 146, \"\\\\u2027\": 147, \"\\\\u202d\": 148, \"\\\\u215b\": 149, \"\\\\u00e5\": 150, \"\\\\ufb02\": 151, \"`\": 152, \"\\\\u00c1\": 153, \"\\\\u00eb\": 154, \"\\\\u0097\": 155, \"\\\\u001a\": 156, \"\\\\u00f8\": 157, \"\\\\u2153\": 158, \"|\": 159, \"\\\\u01b0\": 160, \"\\\\u0092\": 161, \"\\\\u00b4\": 162, \"\\\\u2012\": 163, \"\\\\u00c2\": 164, \"\\\\u2423\": 165, \"\\\\u00a4\": 166, \"\\\\u201f\": 167, \"\\\\u00a0\": 168, \"\\\\u01a1\": 169, \"\\\\u0103\": 170, \"\\\\u0300\": 171, \"\\\\u215e\": 172, \"\\\\u20ac\": 173, \"~\": 174, \"\\\\u0095\": 175}'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_SIGN = '‚ê£'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=True,\n",
    "    filters='',\n",
    "    lower=False,\n",
    "    split=''\n",
    ")\n",
    "\n",
    "# Stop word is not a part of recipes, but tokenizer must know about it as well.\n",
    "tokenizer.fit_on_texts([STOP_SIGN])\n",
    "\n",
    "tokenizer.fit_on_texts(dataset_filtered)\n",
    "\n",
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY_SIZE:  176\n"
     ]
    }
   ],
   "source": [
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1\n",
    "\n",
    "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.index_word[5])\n",
    "print(tokenizer.index_word[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' ', 'e', 'a', 't', 'o', 'n', 'i', 'r', 's', 'l', 'd', 'h', 'c', 'u', 'p', '\\n', 'm', 'g', 'b', ',', '.', 'f', 'w', '‚Ä¢', 'k', '1', 'v', 'y', '2', '/', '‚ñ™', 'Ô∏é', 'S', '4', 'C', '-', '3', 'x', 'P', '5', '0', '(', ')', 'A', 'B', 'z', 'j', 'F', 'T', 'R', 'üìó', 'ü•ï', 'üìù', 'I', 'M', ';', 'q', 'D', 'W', '8', 'G', '6', 'L', 'H', ':', '7', 'O', \"'\", 'E', 'K', '9', 'U', 'N', 'V', 'J', '¬Æ', '¬∞', '√©', '\"', 'Y', 'Q', '*', '!', 'Z', '‚Äì', '&', '%', '√±', '√®', '‚Ñ¢', '√Æ', 'X', '?', '¬ø', '‚Äî', '√ß', '#', '¬Ω', '√≠', '=', '‚Äô', '√¢', '¬©', '¬º', '+', '>', '$', '<', '√°', '√≥', '√∫', '√Ø', '√â', '√ª', ']', '[', '√º', '√™', '√†', '_', '\\xad', '¬æ', '‚Äö', 'ÔøΩ', '¬∫', '‚ÅÑ', '√§', '√ö', '√π', 'ÃÅ', '}', '√∂', '{', '√¨', '√¥', '\\x96', '‚Äù', '√ó', 'Àö', '¬ª', '@', '¬ß', '\\\\', '‚óä', '‚Ä±', '‚Äú', '‚Äß', '\\u202d', '‚Öõ', '√•', 'Ô¨Ç', '`', '√Å', '√´', '\\x97', '\\x1a', '√∏', '‚Öì', '|', '∆∞', '\\x92', '¬¥', '‚Äí', '√Ç', '‚ê£', '¬§', '‚Äü', '\\xa0', '∆°', 'ƒÉ', 'ÃÄ', '‚Öû', '‚Ç¨', '~', '\\x95']\n"
     ]
    }
   ],
   "source": [
    "array_vocabulary = tokenizer.sequences_to_texts([[word_index] for word_index in range(VOCABULARY_SIZE)])\n",
    "print([char for char in array_vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[51, 1, 28, 2, 9]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['üìó yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized dataset size 100212\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized = tokenizer.texts_to_sequences(dataset_filtered)\n",
    "\n",
    "print('Vectorized dataset size', len(dataset_vectorized)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 1, 33, 10, 5, 23, 1, 35, 5, 5] ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vectorized[0][:10], '...') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó   S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \n",
      " \n",
      " ü•ï \n",
      " \n",
      " ‚Ä¢   4   s k i n l e s s ,   b o n e l e s s   c h i c k e n   b r e a s t   h a l v e s   \n",
      " ‚Ä¢   2   t a b l e s p o o n s   b u t t e r   \n",
      " ‚Ä¢   2   ( 1 0 . 7 5   o u n c e )   c a n s   c o n d e n s e d   c r e a m   o f   c h i c k e n   s o u p   \n",
      " ‚Ä¢   1   o n i o n ,   f i n e l y   d i c e d   \n",
      " ‚Ä¢   2   ( 1 0   o u n c e )   p a c k a g e s   r e f r i g e r a t e d   b i s c u i t   d o u g h ,   t o r n   i n t o   p i e c e s   \n",
      " \n",
      " üìù \n",
      " \n",
      " ‚ñ™ Ô∏é   P l a c e   t h e   c h i c k e n ,   b u t t e r ,   s o u p ,   a n d   o n i o n   i n   a   s l o w   c o o k e r ,   a n d   f i l l   w i t h   e n o u g h   w a t e r   t o   c o v e r . \n",
      " ‚ñ™ Ô∏é   C o v e r ,   a n d   c o o k   f o r   5   t o   6   h o u r s   o n   H i g h .   A b o u t   3 0   m i n u t e s   b e f o r e   s e r v i n g ,   p l a c e   t h e   t o r n   b i s c u i t   d o u g h   i n   t h e   s l o w   c o o k e r .   C o o k   u n t i l   t h e   d o u g h   i s   n o   l o n g e r   r a w   i n   t h e   c e n t e r . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recipe_sequence_to_string(recipe_sequence):\n",
    "    recipe_stringified = tokenizer.sequences_to_texts([recipe_sequence])[0]\n",
    "    print(recipe_stringified)\n",
    "\n",
    "recipe_sequence_to_string(dataset_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #1 length: 546\n",
      "Recipe #2 length: 401\n",
      "Recipe #3 length: 671\n",
      "Recipe #4 length: 736\n",
      "Recipe #5 length: 1518\n",
      "Recipe #6 length: 740\n",
      "Recipe #7 length: 839\n",
      "Recipe #8 length: 667\n",
      "Recipe #9 length: 1264\n",
      "Recipe #10 length: 854\n"
     ]
    }
   ],
   "source": [
    "for recipe_index, recipe in enumerate(dataset_vectorized[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index + 1, len(recipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #0 length: 2001\n",
      "Recipe #1 length: 2001\n",
      "Recipe #2 length: 2001\n",
      "Recipe #3 length: 2001\n",
      "Recipe #4 length: 2001\n",
      "Recipe #5 length: 2001\n",
      "Recipe #6 length: 2001\n",
      "Recipe #7 length: 2001\n",
      "Recipe #8 length: 2001\n",
      "Recipe #9 length: 2001\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure\n",
    "    # that all recipes will have at least 1 stops sign at the end,\n",
    "    # since each sequence will be shifted and truncated afterwards\n",
    "    # (to generate X and Y sequences).\n",
    "    maxlen=MAX_RECIPE_LENGTH-1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_RECIPE_LENGTH+1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "for recipe_index, recipe in enumerate(dataset_vectorized_padded[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index, len(recipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó   S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \n",
      " \n",
      " ü•ï \n",
      " \n",
      " ‚Ä¢   4   s k i n l e s s ,   b o n e l e s s   c h i c k e n   b r e a s t   h a l v e s   \n",
      " ‚Ä¢   2   t a b l e s p o o n s   b u t t e r   \n",
      " ‚Ä¢   2   ( 1 0 . 7 5   o u n c e )   c a n s   c o n d e n s e d   c r e a m   o f   c h i c k e n   s o u p   \n",
      " ‚Ä¢   1   o n i o n ,   f i n e l y   d i c e d   \n",
      " ‚Ä¢   2   ( 1 0   o u n c e )   p a c k a g e s   r e f r i g e r a t e d   b i s c u i t   d o u g h ,   t o r n   i n t o   p i e c e s   \n",
      " \n",
      " üìù \n",
      " \n",
      " ‚ñ™ Ô∏é   P l a c e   t h e   c h i c k e n ,   b u t t e r ,   s o u p ,   a n d   o n i o n   i n   a   s l o w   c o o k e r ,   a n d   f i l l   w i t h   e n o u g h   w a t e r   t o   c o v e r . \n",
      " ‚ñ™ Ô∏é   C o v e r ,   a n d   c o o k   f o r   5   t o   6   h o u r s   o n   H i g h .   A b o u t   3 0   m i n u t e s   b e f o r e   s e r v i n g ,   p l a c e   t h e   t o r n   b i s c u i t   d o u g h   i n   t h e   s l o w   c o o k e r .   C o o k   u n t i l   t h e   d o u g h   i s   n o   l o n g e r   r a w   i n   t h e   c e n t e r . \n",
      " ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n"
     ]
    }
   ],
   "source": [
    "recipe_sequence_to_string(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(2001,), dtype=tf.int32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw recipe:\n",
      " [ 51   1  33 ... 165 165 165] \n",
      "\n",
      "\n",
      "\n",
      "Stringified recipe:\n",
      "\n",
      "üìó   S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \n",
      " \n",
      " ü•ï \n",
      " \n",
      " ‚Ä¢   4   s k i n l e s s ,   b o n e l e s s   c h i c k e n   b r e a s t   h a l v e s   \n",
      " ‚Ä¢   2   t a b l e s p o o n s   b u t t e r   \n",
      " ‚Ä¢   2   ( 1 0 . 7 5   o u n c e )   c a n s   c o n d e n s e d   c r e a m   o f   c h i c k e n   s o u p   \n",
      " ‚Ä¢   1   o n i o n ,   f i n e l y   d i c e d   \n",
      " ‚Ä¢   2   ( 1 0   o u n c e )   p a c k a g e s   r e f r i g e r a t e d   b i s c u i t   d o u g h ,   t o r n   i n t o   p i e c e s   \n",
      " \n",
      " üìù \n",
      " \n",
      " ‚ñ™ Ô∏é   P l a c e   t h e   c h i c k e n ,   b u t t e r ,   s o u p ,   a n d   o n i o n   i n   a   s l o w   c o o k e r ,   a n d   f i l l   w i t h   e n o u g h   w a t e r   t o   c o v e r . \n",
      " ‚ñ™ Ô∏é   C o v e r ,   a n d   c o o k   f o r   5   t o   6   h o u r s   o n   H i g h .   A b o u t   3 0   m i n u t e s   b e f o r e   s e r v i n g ,   p l a c e   t h e   t o r n   b i s c u i t   d o u g h   i n   t h e   s l o w   c o o k e r .   C o o k   u n t i l   t h e   d o u g h   i s   n o   l o n g e r   r a w   i n   t h e   c e n t e r . \n",
      " ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n"
     ]
    }
   ],
   "source": [
    "for recipe in dataset.take(1):\n",
    "    print('Raw recipe:\\n', recipe.numpy(), '\\n\\n\\n')\n",
    "    print('Stringified recipe:\\n')\n",
    "    recipe_sequence_to_string(recipe.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(TensorSpec(shape=(2000,), dtype=tf.int32, name=None), TensorSpec(shape=(2000,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(recipe):\n",
    "    input_text = recipe[:-1]\n",
    "    target_text = recipe[1:]\n",
    "    \n",
    "    return input_text, target_text\n",
    "\n",
    "dataset_targeted = dataset.map(split_input_target)\n",
    "\n",
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence size: 2000\n",
      "Target sequence size: 2000\n",
      "\n",
      "Input:   'üìó   S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \\n \\n ü•ï \\n \\n ‚Ä¢   4   s k i n l e'\n",
      "Target:  '  S l o w   C o o k e r   C h i c k e n   a n d   D u m p l i n g s \\n \\n ü•ï \\n \\n ‚Ä¢   4   s k i n l e s'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset_targeted.take(1):\n",
    "    print('Input sequence size:', repr(len(input_example.numpy())))\n",
    "    print('Target sequence size:', repr(len(target_example.numpy())))\n",
    "    print()\n",
    "    \n",
    "    input_stringified = tokenizer.sequences_to_texts([input_example.numpy()[:50]])[0]\n",
    "    target_stringified = tokenizer.sequences_to_texts([target_example.numpy()[:50]])[0]\n",
    "    \n",
    "    print('Input:  ', repr(''.join(input_stringified)))\n",
    "    print('Target: ', repr(''.join(target_stringified))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1\n",
      "  input: 51 ('üìó')\n",
      "  expected output: 1 (' ')\n",
      "Step  2\n",
      "  input: 1 (' ')\n",
      "  expected output: 33 ('S')\n",
      "Step  3\n",
      "  input: 33 ('S')\n",
      "  expected output: 10 ('l')\n",
      "Step  4\n",
      "  input: 10 ('l')\n",
      "  expected output: 5 ('o')\n",
      "Step  5\n",
      "  input: 5 ('o')\n",
      "  expected output: 23 ('w')\n",
      "Step  6\n",
      "  input: 23 ('w')\n",
      "  expected output: 1 (' ')\n",
      "Step  7\n",
      "  input: 1 (' ')\n",
      "  expected output: 35 ('C')\n",
      "Step  8\n",
      "  input: 35 ('C')\n",
      "  expected output: 5 ('o')\n",
      "Step  9\n",
      "  input: 5 ('o')\n",
      "  expected output: 5 ('o')\n",
      "Step 10\n",
      "  input: 5 ('o')\n",
      "  expected output: 25 ('k')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:10], target_example[:10])):\n",
    "    print('Step {:2d}'.format(i + 1))\n",
    "    print('  input: {} ({:s})'.format(input_idx, repr(tokenizer.sequences_to_texts([[input_idx.numpy()]])[0])))\n",
    "    print('  expected output: {} ({:s})'.format(target_idx, repr(tokenizer.sequences_to_texts([[target_idx.numpy()]])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(TensorSpec(shape=(2000,), dtype=tf.int32, name=None), TensorSpec(shape=(2000,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_RECIPES_NUM:  100212\n",
      "MAX_RECIPE_LENGTH:  2000\n",
      "VOCABULARY_SIZE:  176\n"
     ]
    }
   ],
   "source": [
    "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)\n",
    "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
    "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_RepeatDataset element_spec=(TensorSpec(shape=(64, 2000), dtype=tf.int32, name=None), TensorSpec(shape=(64, 2000), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "dataset_train = dataset_targeted.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st batch: input_text: tf.Tensor(\n",
      "[[ 51   1  35 ... 165 165 165]\n",
      " [ 51   1  49 ... 165 165 165]\n",
      " [ 51   1  33 ... 165 165 165]\n",
      " ...\n",
      " [ 51   1  45 ... 165 165 165]\n",
      " [ 51   1  61 ... 165 165 165]\n",
      " [ 51   1  67 ... 165 165 165]], shape=(64, 2000), dtype=int32)\n",
      "\n",
      "1st batch: target_text: tf.Tensor(\n",
      "[[  1  35   8 ... 165 165 165]\n",
      " [  1  49   3 ... 165 165 165]\n",
      " [  1  33   7 ... 165 165 165]\n",
      " ...\n",
      " [  1  45   8 ... 165 165 165]\n",
      " [  1  61   8 ... 165 165 165]\n",
      " [  1  67  10 ... 165 165 165]], shape=(64, 2000), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset_train.take(1):\n",
    "    print('1st batch: input_text:', input_text)\n",
    "    print()\n",
    "    print('1st batch: target_text:', target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "tmp_input_array shape: (2, 8)\n",
      "tmp_input_array:\n",
      "[[7 3 6 3 1 9 2 7]\n",
      " [0 5 3 8 5 1 3 2]]\n",
      "\n",
      "tmp_output_array shape: (2, 8, 5)\n",
      "tmp_output_array:\n",
      "[[[-3.77308242e-02  2.33512633e-02  4.87733521e-02  3.46242674e-02\n",
      "   -1.73994079e-02]\n",
      "  [-3.77011076e-02 -2.96924952e-02 -4.61634658e-02 -9.08859074e-05\n",
      "   -4.15291786e-02]\n",
      "  [-1.74199454e-02 -3.64323966e-02 -3.56478095e-02  1.98866986e-02\n",
      "   -3.54797728e-02]\n",
      "  [-3.77011076e-02 -2.96924952e-02 -4.61634658e-02 -9.08859074e-05\n",
      "   -4.15291786e-02]\n",
      "  [-2.53484137e-02  1.19779110e-02  6.42668083e-03 -1.82749033e-02\n",
      "   -2.71266345e-02]\n",
      "  [ 2.76284926e-02  6.01031631e-03 -7.26230070e-03  4.90240566e-02\n",
      "   -2.48480793e-02]\n",
      "  [-4.38097864e-03 -9.37109068e-03  3.76684777e-02 -1.67005062e-02\n",
      "    2.39935629e-02]\n",
      "  [-3.77308242e-02  2.33512633e-02  4.87733521e-02  3.46242674e-02\n",
      "   -1.73994079e-02]]\n",
      "\n",
      " [[-3.68543155e-02 -4.06566635e-02  3.94099094e-02 -1.64303407e-02\n",
      "    7.39607960e-03]\n",
      "  [-4.53221910e-02  3.78735177e-02 -4.72322851e-03 -2.17317697e-02\n",
      "   -3.61805446e-02]\n",
      "  [-3.77011076e-02 -2.96924952e-02 -4.61634658e-02 -9.08859074e-05\n",
      "   -4.15291786e-02]\n",
      "  [ 4.26016562e-02 -2.80370601e-02 -3.98465768e-02  1.04848035e-02\n",
      "    1.88235193e-03]\n",
      "  [-4.53221910e-02  3.78735177e-02 -4.72322851e-03 -2.17317697e-02\n",
      "   -3.61805446e-02]\n",
      "  [-2.53484137e-02  1.19779110e-02  6.42668083e-03 -1.82749033e-02\n",
      "   -2.71266345e-02]\n",
      "  [-3.77011076e-02 -2.96924952e-02 -4.61634658e-02 -9.08859074e-05\n",
      "   -4.15291786e-02]\n",
      "  [-4.38097864e-03 -9.37109068e-03  3.76684777e-02 -1.67005062e-02\n",
      "    2.39935629e-02]]]\n"
     ]
    }
   ],
   "source": [
    "tmp_vocab_size = 10\n",
    "tmp_embedding_size = 5\n",
    "tmp_input_length = 8\n",
    "tmp_batch_size = 2\n",
    "\n",
    "tmp_model = tf.keras.models.Sequential()\n",
    "tmp_model.add(tf.keras.layers.Embedding(\n",
    "  input_dim=tmp_vocab_size,\n",
    "  output_dim=tmp_embedding_size,\n",
    "  input_length=tmp_input_length\n",
    "))\n",
    "# The model will take as input an integer matrix of size (batch, input_length).\n",
    "# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\n",
    "# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "tmp_input_array = np.random.randint(\n",
    "  low=0,\n",
    "  high=tmp_vocab_size,\n",
    "  size=(tmp_batch_size, tmp_input_length)\n",
    ")\n",
    "tmp_model.compile('rmsprop', 'mse')\n",
    "tmp_output_array = tmp_model.predict(tmp_input_array)\n",
    "\n",
    "print('tmp_input_array shape:', tmp_input_array.shape)\n",
    "print('tmp_input_array:')\n",
    "print(tmp_input_array)\n",
    "print()\n",
    "print('tmp_output_array shape:', tmp_output_array.shape)\n",
    "print('tmp_output_array:')\n",
    "print(tmp_output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           45056     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 176)           180400    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,472,432\n",
      "Trainable params: 5,472,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size=VOCABULARY_SIZE,\n",
    "  embedding_dim=256,\n",
    "  rnn_units=1024,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    to_file='model.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2000, 176) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset_train.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the 1st letter of the batch 1st sequense:\n",
      "tf.Tensor(\n",
      "[ 2.0018648e-03 -3.2766589e-03 -1.5681493e-04  1.3910232e-03\n",
      "  1.5669636e-04 -2.1060652e-03 -3.5835709e-03  3.2440103e-03\n",
      "  2.2271501e-03 -3.4974894e-04  6.0762172e-03 -2.7479283e-03\n",
      " -3.9549028e-03 -8.0711674e-05 -2.8785127e-03  2.2815065e-03\n",
      "  1.3460871e-04 -5.0823577e-04 -5.9126071e-03  6.9919359e-03\n",
      " -7.5357929e-03  5.5721134e-04 -2.5775700e-03 -1.5606768e-03\n",
      " -1.0368829e-03  1.6341545e-04  6.0296790e-03 -1.5584026e-03\n",
      "  2.3387771e-03 -3.2446508e-03 -2.1852357e-03 -7.7784306e-04\n",
      " -2.4110251e-03  2.6018377e-03  4.0085008e-03 -6.4888305e-04\n",
      " -1.4631776e-05 -5.6045206e-04  6.2798196e-04 -1.7109476e-03\n",
      "  1.2524310e-03  4.5122178e-03 -4.1605169e-03 -8.0167438e-04\n",
      "  2.4311224e-03 -6.8088109e-04 -2.7990136e-03  6.4655795e-04\n",
      "  3.9326716e-03  1.5779607e-03 -1.8937676e-04 -2.2161601e-03\n",
      "  2.7333125e-03 -2.5492590e-03 -1.3986669e-03 -4.7045820e-03\n",
      " -6.9096475e-04  2.2106783e-03  1.4988581e-03 -1.5864802e-03\n",
      "  3.6679716e-03  1.1072258e-03  3.1479164e-03  4.2304099e-03\n",
      "  4.1828086e-03 -4.6453215e-03 -9.0907514e-04  6.8881288e-03\n",
      "  1.0366288e-03  2.0569579e-03 -4.0325741e-03 -5.6329032e-04\n",
      " -8.7436978e-03 -3.2818946e-03  6.1356141e-03  8.8073971e-04\n",
      " -1.3637156e-03 -2.9605459e-03  2.4435564e-03 -1.0703143e-03\n",
      "  3.9873840e-03  6.3571101e-03  4.6840906e-03 -2.8505693e-03\n",
      " -2.6508234e-04  1.6656711e-03 -3.1787336e-03 -5.9809070e-03\n",
      "  1.9156111e-03 -2.4585375e-03  8.1398641e-04 -5.4710585e-04\n",
      "  1.1333423e-03  5.0427355e-03  1.9497969e-03  1.2209761e-04\n",
      " -4.0017068e-04  6.8270797e-03 -6.3385619e-03 -5.7661142e-03\n",
      " -1.6064381e-03  5.9159980e-03 -5.7378989e-03  3.7634489e-03\n",
      "  2.3178994e-03 -3.2260183e-03 -3.9559521e-04 -4.5125387e-03\n",
      " -1.3946064e-03  2.3868057e-04  3.7800968e-03 -4.1164067e-03\n",
      " -2.3885104e-03  2.3574480e-03  3.0802535e-03  2.4065215e-03\n",
      " -2.0153124e-03  3.2981532e-04  1.6018115e-03 -5.1185079e-03\n",
      "  8.2249974e-04  1.8109573e-03 -2.8473176e-03  7.5769867e-04\n",
      "  1.4617546e-03  1.0781249e-02 -2.9564840e-03 -4.7293655e-04\n",
      " -7.1909768e-04 -2.3320515e-03  1.3847705e-03 -4.5858254e-03\n",
      " -4.0788245e-03  3.9235367e-03  1.6974187e-03  5.3218678e-03\n",
      "  2.9896824e-03 -4.8682513e-03  1.9548265e-03 -1.7089887e-03\n",
      " -2.5701188e-03 -2.8157255e-03 -2.5109211e-03  3.2773113e-03\n",
      " -2.4421550e-03 -3.4525685e-03 -5.7903817e-04  1.4682086e-03\n",
      "  3.5075881e-03  5.3652069e-03  1.9608685e-03 -2.7924592e-03\n",
      " -1.4162905e-03  1.2533688e-03  2.4977277e-03 -1.4393394e-03\n",
      "  2.9967683e-03  2.4125373e-03  2.3650951e-03 -3.1421527e-03\n",
      " -1.0409926e-03  3.3952373e-03  4.8454492e-03 -8.0312807e-03\n",
      " -3.8333270e-03  4.1263578e-03  1.2015533e-03 -5.2665160e-03\n",
      "  1.4908321e-03  2.1927478e-03 -5.8792178e-03  2.9053129e-03\n",
      "  1.9200867e-03  2.1055182e-03  3.1168796e-03 -1.9900010e-03], shape=(176,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
    "print(example_batch_predictions[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 2 0 2]], shape=(1, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# logits is 2-D Tensor with shape [batch_size, num_classes].\n",
    "# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n",
    "# In the example below we say that the probability for class \"0\"\n",
    "# (element with index 0) is low but the probability for class \"2\" is much higher.\n",
    "tmp_logits = [\n",
    "  [-0.95, 0, 0.95],\n",
    "];\n",
    "\n",
    "# Let's generate 5 samples. Each sample is a class index. Class probabilities \n",
    "# are being taken into account (we expect to see more samples of class \"2\").\n",
    "tmp_samples = tf.random.categorical(\n",
    "    logits=tmp_logits,\n",
    "    num_samples=5\n",
    ")\n",
    "\n",
    "print(tmp_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    logits=example_batch_predictions[0],\n",
    "    num_samples=1\n",
    ")\n",
    "\n",
    "sampled_indices = tf.squeeze(\n",
    "    input=sampled_indices,\n",
    "    axis=-1\n",
    ").numpy()\n",
    "\n",
    "sampled_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168,  58,  32, 143,  53, 114, 125, 149,   2, 107,  39,  11, 104,\n",
       "        95, 153,  66,  22,  94, 158,  65, 144,  56,  35,  98,  22, 166,\n",
       "        43, 149, 147,  85,  93, 122, 164, 164,  69,  26, 168, 173, 171,\n",
       "        20,  50,  46,  70, 149, 138, 158, 157,  48,   7,  76, 168,   2,\n",
       "        43,  91, 120, 137,  53,  23, 127,  28,   6,  90, 159,  48,  85,\n",
       "       102,  99, 141, 102,  75, 110, 138, 171,  16,  82,  62,  53,  86,\n",
       "       132,  50,   8,  47, 107, 161,  36, 164,  18, 113, 131,  64, 109,\n",
       "       108, 157, 104,  74, 142,  23, 145, 113,  30], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " 'üìó   B l a c k b e r r y   C o b b l e r   I I \\n \\n ü•ï \\n \\n ‚Ä¢   1   c u p   a l l - p u r p o s e   f l'\n",
      "\n",
      "Next char prediction:\n",
      " '\\xa0 D Ô∏é \\\\ üìù √ª ¬∫ ‚Öõ e $ P d ¬º ‚Äî √Å 7 f ¬ø ‚Öì : ‚óä ; C ¬Ω f ¬§ ) ‚Öõ ‚Äß ‚Äì ? ¬æ √Ç √Ç E 1 \\xa0 ‚Ç¨ ÃÄ , R z K ‚Öõ √ó ‚Öì √∏ F i ¬Æ'\n"
     ]
    }
   ],
   "source": [
    "print('Input:\\n', repr(''.join(tokenizer.sequences_to_texts([input_example_batch[0].numpy()[:50]]))))\n",
    "print()\n",
    "print('Next char prediction:\\n', repr(''.join(tokenizer.sequences_to_texts([sampled_indices[:50]])))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 2000, 176)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss.shape:       (64, 2000)\n",
      "scalar_loss:       5.149146\n"
     ]
    }
   ],
   "source": [
    "# An objective function.\n",
    "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss.shape:      \", example_batch_loss.shape)\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoints directory.\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           10\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  50\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = 50\n",
    "\n",
    "print('EPOCHS:          ', EPOCHS)\n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "50/50 [==============================] - 31208s 635s/step - loss: 1.7467\n",
      "Epoch 3/10\n",
      "47/50 [===========================>..] - ETA: 1:03:21 - loss: 1.2421"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        early_stopping_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Saving the trained model to file (to be able to re-use it later).\n",
    "model_name = 'recipe_generation_rnn_raw.h5'\n",
    "model.save(model_name, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m=\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mrecipe_generation_rnn_raw.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m      3\u001b[0m \u001b[39m# def render_training_history(training_history):\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#     loss = training_history.history['loss']\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[39m# render_training_history(history)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "def render_training_history(training_history):\n",
    "    loss = training_history.history['loss']\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss, label='Training set')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "render_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_batch_size = 1\n",
    "\n",
    "model_simplified = build_model(vocab_size, embedding_dim, rnn_units, simplified_batch_size)\n",
    "model_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model_simplified.build(tf.TensorShape([simplified_batch_size, None]))\n",
    "\n",
    "model_simplified.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simplified.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    \n",
    "    padded_start_string = STOP_WORD_TITLE + start_string\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1.\n",
    "    model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1, 0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "\n",
    "        text_generated.append(next_character)\n",
    "\n",
    "    return (padded_start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(model):\n",
    "    recipe_length = 1000\n",
    "    try_letters = ['', '\\n', 'A', 'B', 'C', 'O', 'L', 'Mushroom', 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_temperature = [1.0, 0.8, 0.4, 0.2]\n",
    "\n",
    "    for letter in try_letters:\n",
    "        for temperature in try_temperature:\n",
    "            generated_text = generate_text(\n",
    "                model,\n",
    "                start_string=letter,\n",
    "                num_generate = recipe_length,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            print(f'Attempt: \"{letter}\" + {temperature}')\n",
    "            print('-----------------------------------')\n",
    "            print(generated_text)\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_combinations(model_simplified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
